{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c95da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.optim import Adam\n",
    "import torchvision\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5c0dd2",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95749962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256 \n",
    "transform = transforms.Compose( \n",
    "    [ \n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = CIFAR10( \n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_set = CIFAR10(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "trainloader = DataLoader( \n",
    "    train_set, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f1db9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5cb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=1, padding='same'),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding='same'),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.conv_layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.conv_layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.conv_layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.conv_layer6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.conv_layer7 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.conv_layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.conv_layer9 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.conv_layer10 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.conv_layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.conv_layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, stride=1, padding='same'),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 512),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.fc_layer2 = nn.Linear(512, n_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.conv_layer3(x)\n",
    "        x = self.conv_layer4(x)\n",
    "        x = self.conv_layer5(x)\n",
    "        x = self.conv_layer6(x)\n",
    "        x = self.conv_layer7(x)\n",
    "        x = self.conv_layer8(x)\n",
    "        x = self.conv_layer9(x)\n",
    "        x = self.conv_layer10(x)\n",
    "        x = self.conv_layer11(x)\n",
    "        x = self.conv_layer12(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_layer1(x)\n",
    "        out = self.fc_layer2(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4a0930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (conv_layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (conv_layer2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (conv_layer3): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_layer4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (conv_layer5): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (conv_layer6): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_layer7): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (conv_layer8): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (conv_layer9): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_layer10): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (conv_layer11): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (conv_layer12): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): SiLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc_layer1): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (1): SiLU()\n",
      "  )\n",
      "  (fc_layer2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model =CNNModel(10)\n",
    "\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d55a2",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3aa02f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f86ceed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0 \n",
    "    running_correct = 0 \n",
    "    total = 0 \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images) \n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * running_correct / total \n",
    "    test_loss = test_loss / len(testloader)\n",
    "\n",
    "    return test_loss, accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2fdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "max_epoch = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee79a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.1650, Accuracy: 19.56%, Test Loss: 2.1455, Test Accuracy: 21.10%\n",
      "Epoch [2/50], Loss: 2.1507, Accuracy: 20.32%, Test Loss: 2.1373, Test Accuracy: 20.28%\n",
      "Epoch [3/50], Loss: 2.1415, Accuracy: 20.94%, Test Loss: 2.1290, Test Accuracy: 20.87%\n",
      "Epoch [4/50], Loss: 2.1327, Accuracy: 21.24%, Test Loss: 2.1153, Test Accuracy: 22.44%\n",
      "Epoch [5/50], Loss: 2.1279, Accuracy: 21.32%, Test Loss: 2.1118, Test Accuracy: 22.02%\n",
      "Epoch [6/50], Loss: 2.1237, Accuracy: 21.65%, Test Loss: 2.1126, Test Accuracy: 21.02%\n",
      "Epoch [7/50], Loss: 2.1030, Accuracy: 22.59%, Test Loss: 2.1345, Test Accuracy: 20.75%\n",
      "Epoch [8/50], Loss: 2.0911, Accuracy: 23.75%, Test Loss: 2.0646, Test Accuracy: 24.31%\n",
      "Epoch [9/50], Loss: 2.0726, Accuracy: 24.56%, Test Loss: 2.1041, Test Accuracy: 22.56%\n",
      "Epoch [10/50], Loss: 2.0506, Accuracy: 25.51%, Test Loss: 2.0290, Test Accuracy: 27.28%\n",
      "Epoch [11/50], Loss: 2.0204, Accuracy: 26.64%, Test Loss: 2.0307, Test Accuracy: 26.26%\n",
      "Epoch [12/50], Loss: 2.0082, Accuracy: 27.34%, Test Loss: 2.0401, Test Accuracy: 25.92%\n",
      "Epoch [13/50], Loss: 1.9961, Accuracy: 27.49%, Test Loss: 1.9631, Test Accuracy: 28.72%\n",
      "Epoch [14/50], Loss: 1.9717, Accuracy: 28.42%, Test Loss: 1.9535, Test Accuracy: 28.65%\n",
      "Epoch [15/50], Loss: 1.9550, Accuracy: 29.35%, Test Loss: 1.9423, Test Accuracy: 29.19%\n",
      "Epoch [16/50], Loss: 1.9400, Accuracy: 29.83%, Test Loss: 1.9132, Test Accuracy: 31.74%\n",
      "Epoch [17/50], Loss: 1.8980, Accuracy: 31.74%, Test Loss: 1.8656, Test Accuracy: 32.43%\n",
      "Epoch [18/50], Loss: 1.8550, Accuracy: 33.27%, Test Loss: 1.8376, Test Accuracy: 34.11%\n",
      "Epoch [19/50], Loss: 1.8222, Accuracy: 34.24%, Test Loss: 1.8060, Test Accuracy: 34.61%\n",
      "Epoch [20/50], Loss: 1.7970, Accuracy: 35.44%, Test Loss: 1.7805, Test Accuracy: 35.90%\n",
      "Epoch [21/50], Loss: 1.7640, Accuracy: 36.61%, Test Loss: 1.7922, Test Accuracy: 35.76%\n",
      "Epoch [22/50], Loss: 1.7432, Accuracy: 37.43%, Test Loss: 1.7345, Test Accuracy: 37.25%\n",
      "Epoch [23/50], Loss: 1.7147, Accuracy: 38.52%, Test Loss: 1.7175, Test Accuracy: 38.46%\n",
      "Epoch [24/50], Loss: 1.6886, Accuracy: 39.34%, Test Loss: 1.6806, Test Accuracy: 39.41%\n",
      "Epoch [25/50], Loss: 1.6570, Accuracy: 40.67%, Test Loss: 1.6984, Test Accuracy: 38.39%\n",
      "Epoch [26/50], Loss: 1.6368, Accuracy: 41.72%, Test Loss: 1.6864, Test Accuracy: 39.78%\n",
      "Epoch [27/50], Loss: 1.6047, Accuracy: 42.66%, Test Loss: 1.6392, Test Accuracy: 41.39%\n",
      "Epoch [28/50], Loss: 1.5766, Accuracy: 43.88%, Test Loss: 1.6104, Test Accuracy: 42.60%\n",
      "Epoch [29/50], Loss: 1.5516, Accuracy: 44.72%, Test Loss: 1.6210, Test Accuracy: 42.22%\n",
      "Epoch [30/50], Loss: 1.5202, Accuracy: 45.83%, Test Loss: 1.6233, Test Accuracy: 42.79%\n",
      "Epoch [31/50], Loss: 1.4861, Accuracy: 47.02%, Test Loss: 1.5947, Test Accuracy: 43.56%\n",
      "Epoch [32/50], Loss: 1.4555, Accuracy: 48.09%, Test Loss: 1.5753, Test Accuracy: 44.32%\n",
      "Epoch [33/50], Loss: 1.4133, Accuracy: 49.69%, Test Loss: 1.5577, Test Accuracy: 45.32%\n",
      "Epoch [34/50], Loss: 1.3703, Accuracy: 51.39%, Test Loss: 1.5688, Test Accuracy: 45.25%\n",
      "Epoch [35/50], Loss: 1.3261, Accuracy: 52.93%, Test Loss: 1.5585, Test Accuracy: 45.54%\n",
      "Epoch [36/50], Loss: 1.2721, Accuracy: 54.95%, Test Loss: 1.5861, Test Accuracy: 44.66%\n",
      "Epoch [37/50], Loss: 1.2146, Accuracy: 57.00%, Test Loss: 1.5815, Test Accuracy: 45.49%\n",
      "Epoch [38/50], Loss: 1.1498, Accuracy: 59.46%, Test Loss: 1.6102, Test Accuracy: 46.35%\n",
      "Epoch [39/50], Loss: 1.0841, Accuracy: 61.53%, Test Loss: 1.6688, Test Accuracy: 44.83%\n",
      "Epoch [40/50], Loss: 0.9970, Accuracy: 64.74%, Test Loss: 1.7073, Test Accuracy: 46.28%\n",
      "Epoch [41/50], Loss: 0.9235, Accuracy: 67.45%, Test Loss: 1.7457, Test Accuracy: 45.48%\n",
      "Epoch [42/50], Loss: 0.8461, Accuracy: 70.41%, Test Loss: 1.8014, Test Accuracy: 45.87%\n",
      "Epoch [43/50], Loss: 0.7658, Accuracy: 73.26%, Test Loss: 1.8476, Test Accuracy: 45.85%\n",
      "Epoch [44/50], Loss: 0.6753, Accuracy: 76.35%, Test Loss: 1.9570, Test Accuracy: 46.01%\n",
      "Epoch [45/50], Loss: 0.5957, Accuracy: 79.30%, Test Loss: 2.1196, Test Accuracy: 46.39%\n",
      "Epoch [46/50], Loss: 0.5253, Accuracy: 81.84%, Test Loss: 2.1566, Test Accuracy: 45.74%\n",
      "Epoch [47/50], Loss: 0.4654, Accuracy: 83.99%, Test Loss: 2.2887, Test Accuracy: 45.82%\n",
      "Epoch [48/50], Loss: 0.4066, Accuracy: 86.01%, Test Loss: 2.4146, Test Accuracy: 45.79%\n",
      "Epoch [49/50], Loss: 0.3646, Accuracy: 87.48%, Test Loss: 2.4995, Test Accuracy: 45.77%\n",
      "Epoch [50/50], Loss: 0.3308, Accuracy: 88.73%, Test Loss: 2.5496, Test Accuracy: 45.18%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0   \n",
    "    total = 0            \n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "    \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    epoch_accuracy = 100 * running_correct / total\n",
    "    epoch_loss = running_loss / (i + 1)\n",
    "    \n",
    "    test_loss, test_accuracy = evaluate(model, testloader, criterion)\n",
    "    print(f\"Epoch [{epoch + 1}/{max_epoch}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d1e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
